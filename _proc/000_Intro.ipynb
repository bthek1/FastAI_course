{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Getting Started\n",
    "output-file: intro.html\n",
    "title: Getting Started\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for all installs and versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg                    4.3                  hf484d3e_0    pytorch\n",
      "libjpeg-turbo             2.0.0                h9bf148f_0    pytorch\n",
      "pytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch\n",
      "pytorch-cuda              11.8                 h7e8668a_5    pytorch\n",
      "pytorch-ignite            0.4.12                   pypi_0    pypi\n",
      "pytorch-lightning         2.0.7                    pypi_0    pypi\n",
      "pytorch-mutex             1.0                        cuda    pytorch\n",
      "torchaudio                2.0.2               py311_cu118    pytorch\n",
      "torchtriton               2.0.0                     py311    pytorch\n",
      "torchvision               0.15.2              py311_cu118    pytorch\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "!conda list | grep \"pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvcc: command not found\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai                        2.7.12\n",
      "fastbook                      0.0.28\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "!pip list | grep \"fastai\" \n",
    "!pip list | grep \"fastbook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "# Check if CUDA (GPU) is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "#|code-fold: true\n",
    "from fastbook import search_images_ddg\n",
    "from fastdownload import download_url\n",
    "from fastai.vision.all import *\n",
    "from nbdevAuto import functions\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by searching for a bird photo and seeing what kind of result we get. We'll start by getting URLs from a search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "functions.download_pic('bird', n_images = 1, folder = './Data', show_progress=True, recreate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and then download a URL and take a look at it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same with \"forest photos\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "functions.download_pic('forest', folder = './Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#|code-fold: true\n",
    "#|eval: false\n",
    "searches = ('forest','bird')\n",
    "path = Path('Data/bird_or_not')\n",
    "\n",
    "functions.create_data_folder(folder_path=path,\n",
    "                             searches=searches,\n",
    "                             amount=200,\n",
    "                            recreate= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "dls = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=[Resize(192, method='squish')],\n",
    "    \n",
    ")\n",
    "\n",
    "dls = dls.dataloaders(path, bs = 16)\n",
    "\n",
    "dls.show_batch(max_n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here what each of the `DataBlock` parameters means:\n",
    "\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "\n",
    "The inputs to our model are images, and the outputs are categories (in this case, \"bird\" or \"forest\").\n",
    "\n",
    "    get_items=get_image_files, \n",
    "    \n",
    "To find all the inputs to our model, run the `get_image_files` function (which returns a list of all image files in a path).\n",
    "\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "\n",
    "Split the data into training and validation sets randomly, using 20% of the data for the validation set.\n",
    "\n",
    "    get_y=parent_label,\n",
    "\n",
    "The labels (`y` values) is the name of the `parent` of each file (i.e. the name of the folder they're in, which will be *bird* or *forest*).\n",
    "\n",
    "    item_tfms=[Resize(192, method='squish')]\n",
    "\n",
    "Before training, resize each image to 192x192 pixels by \"squishing\" it (as opposed to cropping it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning the model\n",
    "Now we're ready to train our model. The fastest widely used computer vision model is `resnet18`. You can train this in a few minutes, even on a CPU! (On a GPU, it generally takes under 10 seconds...)\n",
    "\n",
    "`fastai` comes with a helpful `fine_tune()` method which automatically uses best practices for fine tuning a pre-trained model, so we'll use that.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "timm.list_models('resnet1*')[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "learn = vision_learner(dls, 'resnet18', metrics=error_rate)\n",
    "learn.fine_tune(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Use our model (and build your own!)\n",
    "Let's see what our model thinks about that bird we downloaded at the start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "??PILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "is_bird,_,probs = learn.predict(PILImage.create('Data/bird0.jpg'))\n",
    "print(f\"This is a: {is_bird}.\")\n",
    "print(f\"Probability it's a bird: {probs[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "functions.classify_images(learn, 'Data/bird0.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Is Not Just for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - SegmentationDataLoaders - Easier than datablocks \n",
    "  \n",
    "```python\n",
    "path = untar_data(URLs.CAMVID_TINY)\n",
    "dls = SegmentationDataLoaders.from_label_func(\n",
    "    path, bs=8, fnames = get_image_files(path/\"images\"),\n",
    "    label_func = lambda o: path/'labels'/f'{o.stem}_P{o.suffix}',\n",
    "    codes = np.loadtxt(path/'codes.txt', dtype=str)\n",
    ")\n",
    "\n",
    "learn = unet_learner(dls, resnet34)\n",
    "learn.fine_tune(8)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tabular analysis - income prediction\n",
    "\n",
    "```python\n",
    "from fastai.tabular.all import *\n",
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "\n",
    "dls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n",
    "    cat_names = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                 'relationship', 'race'],\n",
    "    cont_names = ['age', 'fnlwgt', 'education-num'],\n",
    "    procs = [Categorify, FillMissing, Normalize])\n",
    "\n",
    "learn = tabular_learner(dls, metrics=accuracy)\n",
    "learn.fit_one_cycle(3)\n",
    "\n",
    "dls.show_batch()\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Collaboration filtering - ratings/ recommendations\n",
    "\n",
    "```python\n",
    "from fastai.collab import *\n",
    "path = untar_data(URLs.ML_SAMPLE)\n",
    "dls = CollabDataLoaders.from_csv(path/'ratings.csv')\n",
    "learn = collab_learner(dls, y_range=(0.5,5.5))\n",
    "learn.fine_tune(10)\n",
    "learn.show_results()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example\n",
    "```python\n",
    "from fastai.text.all import *\n",
    "\n",
    "dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test', bs=32)\n",
    "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\n",
    "learn.fine_tune(4, 1e-2)\n",
    "```\n",
    "\n",
    "This reduces the batch size to 32 (we will explain this later). If you keep hitting the same error, change 32 to 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example\n",
    "```python\n",
    "from fastai.text.all import *\n",
    "\n",
    "dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test')\n",
    "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, \n",
    "                                metrics=accuracy)\n",
    "learn.fine_tune(4, 1e-2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
