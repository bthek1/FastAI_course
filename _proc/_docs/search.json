[
  {
    "objectID": "lession1.html",
    "href": "lession1.html",
    "title": "Lession 1:",
    "section": "",
    "text": "!conda list | grep \"pytorch\"\n\nffmpeg                    4.3                  hf484d3e_0    pytorch\npytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch\npytorch-cuda              11.8                 h7e8668a_5    pytorch\npytorch-mutex             1.0                        cuda    pytorch\ntorchaudio                2.0.2               py311_cu118    pytorch\ntorchtriton               2.0.0                     py311    pytorch\ntorchvision               0.15.2              py311_cu118    pytorch\n\n\n\n!nvcc --version\n\n/bin/bash: line 1: nvcc: command not found\n\n\n\n!pip list | grep \"fastai\"\n\nfastai                    2.7.12\n\n\n\n!pip list | grep \"fastbook\"\n\nfastbook                  0.0.29\n\n\n\nimport torch\n\n\ntorch.cuda.is_available()\n\nTrue"
  },
  {
    "objectID": "lession1.html#check-for-all-installs-and-versions",
    "href": "lession1.html#check-for-all-installs-and-versions",
    "title": "Lession 1:",
    "section": "",
    "text": "!conda list | grep \"pytorch\"\n\nffmpeg                    4.3                  hf484d3e_0    pytorch\npytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch\npytorch-cuda              11.8                 h7e8668a_5    pytorch\npytorch-mutex             1.0                        cuda    pytorch\ntorchaudio                2.0.2               py311_cu118    pytorch\ntorchtriton               2.0.0                     py311    pytorch\ntorchvision               0.15.2              py311_cu118    pytorch\n\n\n\n!nvcc --version\n\n/bin/bash: line 1: nvcc: command not found\n\n\n\n!pip list | grep \"fastai\"\n\nfastai                    2.7.12\n\n\n\n!pip list | grep \"fastbook\"\n\nfastbook                  0.0.29\n\n\n\nimport torch\n\n\ntorch.cuda.is_available()\n\nTrue"
  },
  {
    "objectID": "lession1.html#generate-data-images",
    "href": "lession1.html#generate-data-images",
    "title": "Lession 1:",
    "section": "Generate Data Images",
    "text": "Generate Data Images\n\nfrom fastbook import search_images_ddg\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\nimport os\n\n\n\nCode\ndef download_pic(name):   \n    # File path of the image\n    image_path = f'{name}.jpg'\n\n    # Check if the image file exists\n    if os.path.exists(image_path):\n        print(\"Image file exists.\")\n    else:\n        print(\"Image file does not exist.\")\n        download_url(\n            search_images_ddg(f'{name}',\n            max_images=1)[0], f'{name}.jpg',\n            show_progress=False\n        )\n\n    return Image.open(f'{name}.jpg').to_thumb(256,256)\n\n\n\n\ndownload_pic\n\n download_pic (name)\n\nLet’s start by searching for a bird photo and seeing what kind of result we get. We’ll start by getting URLs from a search:\n\ndownload_pic('bird')\n\nImage file exists.\n\n\n\n\n\n…and then download a URL and take a look at it:\nNow let’s do the same with “forest photos”:\n\ndownload_pic('forest')\n\nImage file exists.\n\n\n\n\n\n\n\nCode\ndef create_searches_folder(folder_path, searches):\n    for i in searches:\n        dest = (folder_path/i)\n        dest.mkdir(exist_ok=True, parents=True)\n        print(f'created {i} folder')\n\n\n\n\n\ncreate_searches_folder\n\n create_searches_folder (folder_path, searches)\n\n\n\nCode\ndef download_search_images(folder_path, searches, amount):\n    for j in searches:\n        print(f\"downloading images for: {j}\")\n        download_images(\n            folder_path/j,\n            urls=search_images_ddg(f'{j} photo', amount),\n            n_workers=16\n        )\n\n\n\n\n\ndownload_search_images\n\n download_search_images (folder_path, searches, amount)\n\n\n\nCode\ndef verify_pics(folder_path):\n    failed = verify_images(get_image_files(folder_path))\n    failed.map(Path.unlink)\n    print(f\"Number of images failed: {len(failed)}\")\n\n\n\n\n\nverify_pics\n\n verify_pics (folder_path)\n\n\n\nCode\ndef resize_pics(folder_path, searches):\n    for k in searches:\n        resize_images(\n            folder_path/k,\n            max_size=400,\n            dest=folder_path/k,\n            max_workers=8\n        )\n        print(f\"resizing images for: {k}\")\n\n\n\n\n\nresize_pics\n\n resize_pics (folder_path, searches)\n\n\n\nCode\ndef create_data_folder(folder_path, searches, amount):\n    if os.path.exists(folder_path):\n        print(f\"Folder already exists: {folder_path}\")\n    else:   \n        create_searches_folder(folder_path, searches)\n        download_search_images(folder_path, searches, amount)\n        verify_pics(folder_path)\n        resize_pics(folder_path, searches)\n\n\n\n\n\ncreate_data_folder\n\n create_data_folder (folder_path, searches, amount)\n\n\n\nCode\nsearches = 'forest','bird'\npath = Path('bird_or_not')\n\ncreate_data_folder(path, searches, 200)\n\n\nFolder already exists: bird_or_not"
  },
  {
    "objectID": "lession1.html#creating-the-model",
    "href": "lession1.html#creating-the-model",
    "title": "Lession 1:",
    "section": "Creating the model",
    "text": "Creating the model\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path)\n\ndls.show_batch(max_n=6)\n\n\n\n\nHere what each of the DataBlock parameters means:\nblocks=(ImageBlock, CategoryBlock),\nThe inputs to our model are images, and the outputs are categories (in this case, “bird” or “forest”).\nget_items=get_image_files, \nTo find all the inputs to our model, run the get_image_files function (which returns a list of all image files in a path).\nsplitter=RandomSplitter(valid_pct=0.2, seed=42),\nSplit the data into training and validation sets randomly, using 20% of the data for the validation set.\nget_y=parent_label,\nThe labels (y values) is the name of the parent of each file (i.e. the name of the folder they’re in, which will be bird or forest).\nitem_tfms=[Resize(192, method='squish')]\nBefore training, resize each image to 192x192 pixels by “squishing” it (as opposed to cropping it)."
  },
  {
    "objectID": "lession1.html#traning-the-model",
    "href": "lession1.html#traning-the-model",
    "title": "Lession 1:",
    "section": "Traning the model",
    "text": "Traning the model\nNow we’re ready to train our model. The fastest widely used computer vision model is resnet18. You can train this in a few minutes, even on a CPU! (On a GPU, it generally takes under 10 seconds…)\nfastai comes with a helpful fine_tune() method which automatically uses best practices for fine tuning a pre-trained model, so we’ll use that.1\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.834427\n0.670333\n0.234375\n00:02\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.046750\n0.022400\n0.015625\n00:02\n\n\n1\n0.025731\n0.000610\n0.000000\n00:02\n\n\n2\n0.018161\n0.000489\n0.000000\n00:02"
  },
  {
    "objectID": "lession1.html#step-3-use-our-model-and-build-your-own",
    "href": "lession1.html#step-3-use-our-model-and-build-your-own",
    "title": "Lession 1:",
    "section": "Step 3: Use our model (and build your own!)",
    "text": "Step 3: Use our model (and build your own!)\nLet’s see what our model thinks about that bird we downloaded at the start:\n\nis_bird,_,probs = learn.predict(PILImage.create('bird.jpg'))\nprint(f\"This is a: {is_bird}.\")\nprint(f\"Probability it's a bird: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: bird.\nProbability it's a bird: 1.0000"
  },
  {
    "objectID": "lession1.html#deep-learning-is-not-just-for-image-classification",
    "href": "lession1.html#deep-learning-is-not-just-for-image-classification",
    "title": "Lession 1:",
    "section": "Deep Learning Is Not Just for Image Classification",
    "text": "Deep Learning Is Not Just for Image Classification\n\nSegmentationDataLoaders - Easier than datablocks\n\npath = untar_data(URLs.CAMVID_TINY)\ndls = SegmentationDataLoaders.from_label_func(\n    path, bs=8, fnames = get_image_files(path/\"images\"),\n    label_func = lambda o: path/'labels'/f'{o.stem}_P{o.suffix}',\n    codes = np.loadtxt(path/'codes.txt', dtype=str)\n)\n\nlearn = unet_learner(dls, resnet34)\nlearn.fine_tune(8)\n\nTabular analysis - income prediction\n\nfrom fastai.tabular.all import *\npath = untar_data(URLs.ADULT_SAMPLE)\n\ndls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n    cat_names = ['workclass', 'education', 'marital-status', 'occupation',\n                 'relationship', 'race'],\n    cont_names = ['age', 'fnlwgt', 'education-num'],\n    procs = [Categorify, FillMissing, Normalize])\n\nlearn = tabular_learner(dls, metrics=accuracy)\nlearn.fit_one_cycle(3)\n\ndls.show_batch()\n\nCollaboration filtering - ratings/ recommendations\n\nfrom fastai.collab import *\npath = untar_data(URLs.ML_SAMPLE)\ndls = CollabDataLoaders.from_csv(path/'ratings.csv')\nlearn = collab_learner(dls, y_range=(0.5,5.5))\nlearn.fine_tune(10)\nlearn.show_results()\n\nExample\n\nfrom fastai.text.all import *\n\ndls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test', bs=32)\nlearn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\nlearn.fine_tune(4, 1e-2)\nThis reduces the batch size to 32 (we will explain this later). If you keep hitting the same error, change 32 to 16\n\nExample\n\nfrom fastai.text.all import *\n\ndls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test')\nlearn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, \n                                metrics=accuracy)\nlearn.fine_tune(4, 1e-2)"
  },
  {
    "objectID": "naturallanguage.html",
    "href": "naturallanguage.html",
    "title": "Lession 4: Natural Language",
    "section": "",
    "text": "!conda list | grep \"pytorch\"\n\nffmpeg                    4.3                  hf484d3e_0    pytorch\npytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch\npytorch-cuda              11.8                 h7e8668a_5    pytorch\npytorch-ignite            0.4.12                   pypi_0    pypi\npytorch-lightning         2.0.6                    pypi_0    pypi\npytorch-mutex             1.0                        cuda    pytorch\ntorchaudio                2.0.2               py311_cu118    pytorch\ntorchtriton               2.0.0                     py311    pytorch\ntorchvision               0.15.2              py311_cu118    pytorch\n\n\n\n!pip list | grep \"fastai\" \n!pip list | grep \"fastbook\"\n!pip list | grep \"ipywidgets\"\n\nfastai                        2.7.12\nfastbook                      0.0.29\nipywidgets                    7.7.5\n\n\n\nimport torch\n\n\ntorch.cuda.is_available()\n\nTrue"
  },
  {
    "objectID": "naturallanguage.html#initial-checks",
    "href": "naturallanguage.html#initial-checks",
    "title": "Lession 4: Natural Language",
    "section": "",
    "text": "!conda list | grep \"pytorch\"\n\nffmpeg                    4.3                  hf484d3e_0    pytorch\npytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch\npytorch-cuda              11.8                 h7e8668a_5    pytorch\npytorch-ignite            0.4.12                   pypi_0    pypi\npytorch-lightning         2.0.6                    pypi_0    pypi\npytorch-mutex             1.0                        cuda    pytorch\ntorchaudio                2.0.2               py311_cu118    pytorch\ntorchtriton               2.0.0                     py311    pytorch\ntorchvision               0.15.2              py311_cu118    pytorch\n\n\n\n!pip list | grep \"fastai\" \n!pip list | grep \"fastbook\"\n!pip list | grep \"ipywidgets\"\n\nfastai                        2.7.12\nfastbook                      0.0.29\nipywidgets                    7.7.5\n\n\n\nimport torch\n\n\ntorch.cuda.is_available()\n\nTrue"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Lession 1: Getting Started",
    "section": "",
    "text": "!conda list | grep \"pytorch\"\n\nffmpeg                    4.3                  hf484d3e_0    pytorch\npytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch\npytorch-cuda              11.8                 h7e8668a_5    pytorch\npytorch-mutex             1.0                        cuda    pytorch\ntorchaudio                2.0.2               py311_cu118    pytorch\ntorchtriton               2.0.0                     py311    pytorch\ntorchvision               0.15.2              py311_cu118    pytorch\n\n\n\n!nvcc --version\n\n/bin/bash: line 1: nvcc: command not found\n\n\n\n!pip list | grep \"fastai\"\n\nfastai                    2.7.12\n\n\n\n!pip list | grep \"fastbook\"\n\nfastbook                  0.0.29\n\n\n\nimport torch\n\n\ntorch.cuda.is_available()\n\nTrue"
  },
  {
    "objectID": "intro.html#check-for-all-installs-and-versions",
    "href": "intro.html#check-for-all-installs-and-versions",
    "title": "Lession 1: Getting Started",
    "section": "",
    "text": "!conda list | grep \"pytorch\"\n\nffmpeg                    4.3                  hf484d3e_0    pytorch\npytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch\npytorch-cuda              11.8                 h7e8668a_5    pytorch\npytorch-mutex             1.0                        cuda    pytorch\ntorchaudio                2.0.2               py311_cu118    pytorch\ntorchtriton               2.0.0                     py311    pytorch\ntorchvision               0.15.2              py311_cu118    pytorch\n\n\n\n!nvcc --version\n\n/bin/bash: line 1: nvcc: command not found\n\n\n\n!pip list | grep \"fastai\"\n\nfastai                    2.7.12\n\n\n\n!pip list | grep \"fastbook\"\n\nfastbook                  0.0.29\n\n\n\nimport torch\n\n\ntorch.cuda.is_available()\n\nTrue"
  },
  {
    "objectID": "intro.html#generate-data-images",
    "href": "intro.html#generate-data-images",
    "title": "Lession 1: Getting Started",
    "section": "Generate Data Images",
    "text": "Generate Data Images\n\nfrom fastbook import search_images_ddg\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\nimport os\n\n\n\nCode\ndef download_pic(name):   \n    # File path of the image\n    image_path = f'{name}.jpg'\n\n    # Check if the image file exists\n    if os.path.exists(image_path):\n        print(\"Image file exists.\")\n    else:\n        print(\"Image file does not exist.\")\n        download_url(\n            search_images_ddg(f'{name}',\n            max_images=1)[0], f'{name}.jpg',\n            show_progress=False\n        )\n\n    return Image.open(f'{name}.jpg').to_thumb(256,256)\n\n\n\n\ndownload_pic\n\n download_pic (name)\n\nLet’s start by searching for a bird photo and seeing what kind of result we get. We’ll start by getting URLs from a search:\n\ndownload_pic('bird')\n\nImage file exists.\n\n\n\n\n\n…and then download a URL and take a look at it:\nNow let’s do the same with “forest photos”:\n\ndownload_pic('forest')\n\nImage file exists.\n\n\n\n\n\n\n\nCode\ndef create_searches_folder(folder_path, searches):\n    for i in searches:\n        dest = (folder_path/i)\n        dest.mkdir(exist_ok=True, parents=True)\n        print(f'created {i} folder')\n\n\n\n\n\ncreate_searches_folder\n\n create_searches_folder (folder_path, searches)\n\n\n\nCode\ndef download_search_images(folder_path, searches, amount):\n    for j in searches:\n        print(f\"downloading images for: {j}\")\n        download_images(\n            folder_path/j,\n            urls=search_images_ddg(f'{j} photo', amount),\n            n_workers=16\n        )\n\n\n\n\n\ndownload_search_images\n\n download_search_images (folder_path, searches, amount)\n\n\n\nCode\ndef verify_pics(folder_path):\n    failed = verify_images(get_image_files(folder_path))\n    failed.map(Path.unlink)\n    print(f\"Number of images failed: {len(failed)}\")\n\n\n\n\n\nverify_pics\n\n verify_pics (folder_path)\n\n\n\nCode\ndef resize_pics(folder_path, searches):\n    for k in searches:\n        resize_images(\n            folder_path/k,\n            max_size=400,\n            dest=folder_path/k,\n            max_workers=8\n        )\n        print(f\"resizing images for: {k}\")\n\n\n\n\n\nresize_pics\n\n resize_pics (folder_path, searches)\n\n\n\nCode\ndef create_data_folder(folder_path, searches, amount):\n    if os.path.exists(folder_path):\n        print(f\"Folder already exists: {folder_path}\")\n    else:   \n        create_searches_folder(folder_path, searches)\n        download_search_images(folder_path, searches, amount)\n        verify_pics(folder_path)\n        resize_pics(folder_path, searches)\n\n\n\n\n\ncreate_data_folder\n\n create_data_folder (folder_path, searches, amount)\n\n\n\nCode\nsearches = 'forest','bird'\npath = Path('bird_or_not')\n\ncreate_data_folder(path, searches, 200)\n\n\nFolder already exists: bird_or_not"
  },
  {
    "objectID": "intro.html#creating-the-model",
    "href": "intro.html#creating-the-model",
    "title": "Lession 1: Getting Started",
    "section": "Creating the model",
    "text": "Creating the model\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path)\n\ndls.show_batch(max_n=6)\n\n\n\n\nHere what each of the DataBlock parameters means:\nblocks=(ImageBlock, CategoryBlock),\nThe inputs to our model are images, and the outputs are categories (in this case, “bird” or “forest”).\nget_items=get_image_files, \nTo find all the inputs to our model, run the get_image_files function (which returns a list of all image files in a path).\nsplitter=RandomSplitter(valid_pct=0.2, seed=42),\nSplit the data into training and validation sets randomly, using 20% of the data for the validation set.\nget_y=parent_label,\nThe labels (y values) is the name of the parent of each file (i.e. the name of the folder they’re in, which will be bird or forest).\nitem_tfms=[Resize(192, method='squish')]\nBefore training, resize each image to 192x192 pixels by “squishing” it (as opposed to cropping it)."
  },
  {
    "objectID": "intro.html#traning-the-model",
    "href": "intro.html#traning-the-model",
    "title": "Lession 1: Getting Started",
    "section": "Traning the model",
    "text": "Traning the model\nNow we’re ready to train our model. The fastest widely used computer vision model is resnet18. You can train this in a few minutes, even on a CPU! (On a GPU, it generally takes under 10 seconds…)\nfastai comes with a helpful fine_tune() method which automatically uses best practices for fine tuning a pre-trained model, so we’ll use that.1\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.834427\n0.670333\n0.234375\n00:02\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.046750\n0.022400\n0.015625\n00:02\n\n\n1\n0.025731\n0.000610\n0.000000\n00:02\n\n\n2\n0.018161\n0.000489\n0.000000\n00:02"
  },
  {
    "objectID": "intro.html#step-3-use-our-model-and-build-your-own",
    "href": "intro.html#step-3-use-our-model-and-build-your-own",
    "title": "Lession 1: Getting Started",
    "section": "Step 3: Use our model (and build your own!)",
    "text": "Step 3: Use our model (and build your own!)\nLet’s see what our model thinks about that bird we downloaded at the start:\n\nis_bird,_,probs = learn.predict(PILImage.create('bird.jpg'))\nprint(f\"This is a: {is_bird}.\")\nprint(f\"Probability it's a bird: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: bird.\nProbability it's a bird: 1.0000"
  },
  {
    "objectID": "intro.html#deep-learning-is-not-just-for-image-classification",
    "href": "intro.html#deep-learning-is-not-just-for-image-classification",
    "title": "Lession 1: Getting Started",
    "section": "Deep Learning Is Not Just for Image Classification",
    "text": "Deep Learning Is Not Just for Image Classification\n\nSegmentationDataLoaders - Easier than datablocks\n\npath = untar_data(URLs.CAMVID_TINY)\ndls = SegmentationDataLoaders.from_label_func(\n    path, bs=8, fnames = get_image_files(path/\"images\"),\n    label_func = lambda o: path/'labels'/f'{o.stem}_P{o.suffix}',\n    codes = np.loadtxt(path/'codes.txt', dtype=str)\n)\n\nlearn = unet_learner(dls, resnet34)\nlearn.fine_tune(8)\n\nTabular analysis - income prediction\n\nfrom fastai.tabular.all import *\npath = untar_data(URLs.ADULT_SAMPLE)\n\ndls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n    cat_names = ['workclass', 'education', 'marital-status', 'occupation',\n                 'relationship', 'race'],\n    cont_names = ['age', 'fnlwgt', 'education-num'],\n    procs = [Categorify, FillMissing, Normalize])\n\nlearn = tabular_learner(dls, metrics=accuracy)\nlearn.fit_one_cycle(3)\n\ndls.show_batch()\n\nCollaboration filtering - ratings/ recommendations\n\nfrom fastai.collab import *\npath = untar_data(URLs.ML_SAMPLE)\ndls = CollabDataLoaders.from_csv(path/'ratings.csv')\nlearn = collab_learner(dls, y_range=(0.5,5.5))\nlearn.fine_tune(10)\nlearn.show_results()\n\nExample\n\nfrom fastai.text.all import *\n\ndls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test', bs=32)\nlearn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\nlearn.fine_tune(4, 1e-2)\nThis reduces the batch size to 32 (we will explain this later). If you keep hitting the same error, change 32 to 16\n\nExample\n\nfrom fastai.text.all import *\n\ndls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test')\nlearn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, \n                                metrics=accuracy)\nlearn.fine_tune(4, 1e-2)"
  },
  {
    "objectID": "deployment.html",
    "href": "deployment.html",
    "title": "Lession 2: Production",
    "section": "",
    "text": "!conda list | grep \"pytorch\"\n\nffmpeg                    4.3                  hf484d3e_0    pytorch\npytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch\npytorch-cuda              11.8                 h7e8668a_5    pytorch\npytorch-ignite            0.4.12                   pypi_0    pypi\npytorch-lightning         2.0.6                    pypi_0    pypi\npytorch-mutex             1.0                        cuda    pytorch\ntorchaudio                2.0.2               py311_cu118    pytorch\ntorchtriton               2.0.0                     py311    pytorch\ntorchvision               0.15.2              py311_cu118    pytorch\n\n\n\n!nvcc --version\n\n/bin/bash: line 1: nvcc: command not found\n\n\n\n!pip list | grep \"fastai\" \n!pip list | grep \"fastbook\"\n!pip list | grep \"ipywidgets\"\n\nfastai                        2.7.12\nfastbook                      0.0.29\nipywidgets                    7.7.5\n\n\n\nimport torch\n\n\ntorch.cuda.is_available()\n\nTrue"
  },
  {
    "objectID": "deployment.html#initial-checks",
    "href": "deployment.html#initial-checks",
    "title": "Lession 2: Production",
    "section": "",
    "text": "!conda list | grep \"pytorch\"\n\nffmpeg                    4.3                  hf484d3e_0    pytorch\npytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch\npytorch-cuda              11.8                 h7e8668a_5    pytorch\npytorch-ignite            0.4.12                   pypi_0    pypi\npytorch-lightning         2.0.6                    pypi_0    pypi\npytorch-mutex             1.0                        cuda    pytorch\ntorchaudio                2.0.2               py311_cu118    pytorch\ntorchtriton               2.0.0                     py311    pytorch\ntorchvision               0.15.2              py311_cu118    pytorch\n\n\n\n!nvcc --version\n\n/bin/bash: line 1: nvcc: command not found\n\n\n\n!pip list | grep \"fastai\" \n!pip list | grep \"fastbook\"\n!pip list | grep \"ipywidgets\"\n\nfastai                        2.7.12\nfastbook                      0.0.29\nipywidgets                    7.7.5\n\n\n\nimport torch\n\n\ntorch.cuda.is_available()\n\nTrue"
  },
  {
    "objectID": "deployment.html#gather-data",
    "href": "deployment.html#gather-data",
    "title": "Lession 2: Production",
    "section": "Gather Data",
    "text": "Gather Data\n\nfrom fastbook import search_images_ddg\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\nimport os\n\n\n\nCode\ndef download_pic(name):   \n    # File path of the image\n    image_path = f'{name}.jpg'\n\n    # Check if the image file exists\n    if os.path.exists(image_path):\n        print(\"Image file exists.\")\n    else:\n        print(\"Image file does not exist.\")\n        download_url(\n            search_images_ddg(f'{name}',\n            max_images=1)[0], f'{name}.jpg',\n            show_progress=False\n        )\n\n    return Image.open(f'{name}.jpg').to_thumb(256,256)\n\n\n\n\ndownload_pic\n\n download_pic (name)\n\n\ndest = 'grizzly'\ndownload_pic(dest)\n\nImage file exists.\n\n\n\n\n\n\n\nCode\ndef create_searches_folder(folder_path, searches):\n    for i in searches:\n        dest = (folder_path/i)\n        dest.mkdir(exist_ok=True, parents=True)\n        print(f'created {i} folder')\n\n\n\n\n\ncreate_searches_folder\n\n create_searches_folder (folder_path, searches)\n\n\n\nCode\ndef download_search_images(folder_path, searches, amount):\n    for j in searches:\n        print(f\"downloading images for: {j}\")\n        download_images(\n            folder_path/j,\n            urls=search_images_ddg(f'{j} photo', amount),\n            n_workers=16\n        )\n\n\n\n\n\ndownload_search_images\n\n download_search_images (folder_path, searches, amount)\n\n\n\nCode\ndef verify_pics(folder_path):\n    failed = verify_images(get_image_files(folder_path))\n    failed.map(Path.unlink)\n    print(f\"Number of images failed: {len(failed)}\")\n\n\n\n\n\nverify_pics\n\n verify_pics (folder_path)\n\n\n\nCode\ndef resize_pics(folder_path, searches):\n    for k in searches:\n        resize_images(\n            folder_path/k,\n            max_size=400,\n            dest=folder_path/k,\n            max_workers=8\n        )\n        print(f\"resizing images for: {k}\")\n\n\n\n\n\nresize_pics\n\n resize_pics (folder_path, searches)\n\n\n\nCode\ndef create_data_folder(folder_path, searches, amount):\n    if os.path.exists(folder_path):\n        print(f\"Folder already exists: {folder_path}\")\n    else:   \n        create_searches_folder(folder_path, searches)\n        download_search_images(folder_path, searches, amount)\n        verify_pics(folder_path)\n        resize_pics(folder_path, searches)\n\n\n\n\n\ncreate_data_folder\n\n create_data_folder (folder_path, searches, amount)\n\n\n\nCode\nsearches = ('grizzly bears','black bears','teddy bears')\npath = Path('bears')\n\ncreate_data_folder(path, searches, 200)\n\n\nFolder already exists: bears"
  },
  {
    "objectID": "deployment.html#data-augmentation-and-designing-model",
    "href": "deployment.html#data-augmentation-and-designing-model",
    "title": "Lession 2: Production",
    "section": "Data Augmentation and Designing model",
    "text": "Data Augmentation and Designing model\n\n?DataBlock\n\n\nInit signature:\nDataBlock(\n    blocks: 'list' = None,\n    dl_type: 'TfmdDL' = None,\n    getters: 'list' = None,\n    n_inp: 'int' = None,\n    item_tfms: 'list' = None,\n    batch_tfms: 'list' = None,\n    *,\n    get_items=None,\n    splitter=None,\n    get_y=None,\n    get_x=None,\n)\nDocstring:      Generic container to quickly build `Datasets` and `DataLoaders`.\nFile:           ~/mambaforge/envs/fast/lib/python3.11/site-packages/fastai/data/block.py\nType:           type\nSubclasses:     \n\n\n\n\nbears = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\n\n\ndls = bears.dataloaders(path)\n\n\ndls.valid.show_batch(max_n=4, nrows=1)\n\n\n\n\n\nbears = bears.new(item_tfms=Resize(128, ResizeMethod.Squish))\ndls = bears.dataloaders(path)\ndls.valid.show_batch(max_n=4, nrows=1)\n\n\n\n\n\nbears = bears.new(\n    item_tfms=Resize(128, ResizeMethod.Pad, pad_mode='zeros'))\ndls = bears.dataloaders(path)\ndls.valid.show_batch(max_n=4, nrows=1)\n\n\n\n\n\nbears = bears.new(item_tfms=RandomResizedCrop(128, min_scale=0.3))\ndls = bears.dataloaders(path)\ndls.train.show_batch(max_n=4, nrows=1, unique=True)"
  },
  {
    "objectID": "deployment.html#training-your-model-and-using-it-to-clean-your-data",
    "href": "deployment.html#training-your-model-and-using-it-to-clean-your-data",
    "title": "Lession 2: Production",
    "section": "Training Your Model, and Using It to Clean Your Data",
    "text": "Training Your Model, and Using It to Clean Your Data\n\nbears = bears.new(\n    item_tfms=RandomResizedCrop(128, min_scale=0.5),\n    batch_tfms=aug_transforms(mult=1))\ndls = bears.dataloaders(path)\ndls.train.show_batch(max_n=8, nrows=2, unique=False)\n\n\n\n\n\ndls.valid.show_batch(max_n=8, nrows=2, unique=False)"
  },
  {
    "objectID": "deployment.html#training-your-model",
    "href": "deployment.html#training-your-model",
    "title": "Lession 2: Production",
    "section": "Training Your Model",
    "text": "Training Your Model\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(6, nrows=2)\n\n\n\n\n\n\n\n\n\n\n\n\nfrom fastai.vision.widgets import ImageClassifierCleaner\n\n\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#hide\n# for idx in cleaner.delete(): cleaner.fns[idx].unlink()\n# for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)"
  },
  {
    "objectID": "deployment.html#testing",
    "href": "deployment.html#testing",
    "title": "Lession 2: Production",
    "section": "Testing",
    "text": "Testing\n\nsearches = ('grizzly bears','black bears','teddy bears')\nimage= 'grizzly.jpg'\n\n\nis_real,_,probs = learn.predict(PILImage.create(image))\n\nfor index, value in enumerate(searches):\n    np.set_printoptions(suppress=True, precision=4)\n    print(f\"Probability of {value} is :{probs[index]:.5f}.\")\n    \nmax_value, max_index = torch.max(probs, dim=0)\nprint(f\"This is a: {searches[max_index]} with probability: {max_value:.5f}.\")\n\n\nImage.open(image).to_thumb(256,256)\n\n\n\n\n\n\n\n\nProbability of grizzly bears is :0.00002.\nProbability of black bears is :0.99993.\nProbability of teddy bears is :0.00005.\nThis is a: black bears with probability: 0.99993."
  },
  {
    "objectID": "deployment.html#turning-your-model-into-an-online-application",
    "href": "deployment.html#turning-your-model-into-an-online-application",
    "title": "Lession 2: Production",
    "section": "Turning Your Model into an Online Application",
    "text": "Turning Your Model into an Online Application\n\nlearn.export('model.pkl')\n\n\npath = Path()\nfilename = path.ls(file_exts='.pkl')\nfilename[0].name\n\n'model.pkl'\n\n\n\nlearn_inf = load_learner(path/filename[0].name)\n\n\n\n\n\n\n\n\n\n\n\nCPU times: user 263 ms, sys: 13.1 ms, total: 276 ms\nWall time: 96.6 ms\n\n\n('grizzly bears', tensor(1), tensor([2.2252e-05, 9.9993e-01, 4.9021e-05]))\n\n\n\nlearn_inf.dls.vocab\n\n['black bears', 'grizzly bears', 'teddy bears']"
  },
  {
    "objectID": "deployment.html#making-a-widget-application",
    "href": "deployment.html#making-a-widget-application",
    "title": "Lession 2: Production",
    "section": "Making a widget application",
    "text": "Making a widget application\n\nimport ipywidgets as widgets\n\n\nbtn_upload = widgets.FileUpload(\n    accept='',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n    multiple=False  # True to accept multiple files upload else False\n)\nbtn_upload\n\n\n\n\n\nif btn_upload.data != []:\n    img = PILImage.create(btn_upload.data[-1])\n\n\nimg\n\nNameError: name 'img' is not defined\n\n\n\nout_pl = widgets.Output()\nout_pl.clear_output()\nwith out_pl: display(img.to_thumb(128,128))\nout_pl\n\n\npred,pred_idx,probs = learn_inf.predict(img)\n\n\n#hide_output\nlbl_pred = widgets.Label()\nlbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\nlbl_pred\n\n\nbtn_run = widgets.Button(description='Classify')\nbtn_run\n\n\ndef on_click_classify(change):\n    if btn_upload.data != []:\n        img = PILImage.create(btn_upload.data[-1])\n        out_pl.clear_output()\n        with out_pl: display(img.to_thumb(128,128))\n        pred,pred_idx,probs = learn_inf.predict(img)\n        lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\n    else:\n        lbl_pred.value = f'Select image'\n\nbtn_run.on_click(on_click_classify)\n\n\nlbl_pred\n\n\nwidgets.VBox([widgets.Label('Select your bear!'), \n      btn_upload, btn_run, out_pl, lbl_pred])"
  },
  {
    "objectID": "model.html",
    "href": "model.html",
    "title": "Lession 5: From-scratch model",
    "section": "",
    "text": "!conda list | grep \"pytorch\"\n\nffmpeg                    4.3                  hf484d3e_0    pytorch\npytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch\npytorch-cuda              11.8                 h7e8668a_5    pytorch\npytorch-ignite            0.4.12                   pypi_0    pypi\npytorch-lightning         2.0.6                    pypi_0    pypi\npytorch-mutex             1.0                        cuda    pytorch\ntorchaudio                2.0.2               py311_cu118    pytorch\ntorchtriton               2.0.0                     py311    pytorch\ntorchvision               0.15.2              py311_cu118    pytorch\n\n\n\n!pip list | grep \"fastai\" \n!pip list | grep \"fastbook\"\n!pip list | grep \"ipywidgets\"\n\nfastai                        2.7.12\nfastbook                      0.0.29\nipywidgets                    7.7.5\n\n\n\nimport torch\n\n\ntorch.cuda.is_available()\n\nTrue"
  },
  {
    "objectID": "model.html#initial-checks",
    "href": "model.html#initial-checks",
    "title": "Lession 5: From-scratch model",
    "section": "",
    "text": "!conda list | grep \"pytorch\"\n\nffmpeg                    4.3                  hf484d3e_0    pytorch\npytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch\npytorch-cuda              11.8                 h7e8668a_5    pytorch\npytorch-ignite            0.4.12                   pypi_0    pypi\npytorch-lightning         2.0.6                    pypi_0    pypi\npytorch-mutex             1.0                        cuda    pytorch\ntorchaudio                2.0.2               py311_cu118    pytorch\ntorchtriton               2.0.0                     py311    pytorch\ntorchvision               0.15.2              py311_cu118    pytorch\n\n\n\n!pip list | grep \"fastai\" \n!pip list | grep \"fastbook\"\n!pip list | grep \"ipywidgets\"\n\nfastai                        2.7.12\nfastbook                      0.0.29\nipywidgets                    7.7.5\n\n\n\nimport torch\n\n\ntorch.cuda.is_available()\n\nTrue"
  },
  {
    "objectID": "02_NeuralNet.html",
    "href": "02_NeuralNet.html",
    "title": "Lession 3: Neural Net Foundations",
    "section": "",
    "text": "mathematical foundations of deep learning: Stochastic gradient descent (SGD), and the flexibility of linear functions layered with non-linear activation functions."
  },
  {
    "objectID": "02_NeuralNet.html#initial-checks",
    "href": "02_NeuralNet.html#initial-checks",
    "title": "Lession 3: Neural Net Foundations",
    "section": "Initial Checks",
    "text": "Initial Checks\n\n!conda list | grep \"pytorch\"\n\nffmpeg                    4.3                  hf484d3e_0    pytorch\npytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch\npytorch-cuda              11.8                 h7e8668a_5    pytorch\npytorch-ignite            0.4.12                   pypi_0    pypi\npytorch-lightning         2.0.6                    pypi_0    pypi\npytorch-mutex             1.0                        cuda    pytorch\ntorchaudio                2.0.2               py311_cu118    pytorch\ntorchtriton               2.0.0                     py311    pytorch\ntorchvision               0.15.2              py311_cu118    pytorch\n\n\n\n!pip list | grep \"fastai\" \n!pip list | grep \"fastbook\"\n!pip list | grep \"ipywidgets\"\n\nfastai                        2.7.12\nfastbook                      0.0.29\nipywidgets                    7.7.5\n\n\n\nimport torch\n\n\ntorch.cuda.is_available()\n\nTrue"
  },
  {
    "objectID": "lession2.html",
    "href": "lession2.html",
    "title": "Lession 2:",
    "section": "",
    "text": "!conda list | grep \"pytorch\"\n\nffmpeg                    4.3                  hf484d3e_0    pytorch\npytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch\npytorch-cuda              11.8                 h7e8668a_5    pytorch\npytorch-mutex             1.0                        cuda    pytorch\ntorchaudio                2.0.2               py311_cu118    pytorch\ntorchtriton               2.0.0                     py311    pytorch\ntorchvision               0.15.2              py311_cu118    pytorch\n\n\n\n!nvcc --version\n\n/bin/bash: line 1: nvcc: command not found\n\n\n\n!pip list | grep \"fastai\" \n!pip list | grep \"fastbook\"\n!pip list | grep \"ipywidgets\"\n\nfastai                    2.7.12\nfastbook                  0.0.29\nipywidgets                7.7.5\n\n\n\nimport torch\n\n\ntorch.cuda.is_available()\n\nTrue"
  },
  {
    "objectID": "lession2.html#initial-checks",
    "href": "lession2.html#initial-checks",
    "title": "Lession 2:",
    "section": "",
    "text": "!conda list | grep \"pytorch\"\n\nffmpeg                    4.3                  hf484d3e_0    pytorch\npytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch\npytorch-cuda              11.8                 h7e8668a_5    pytorch\npytorch-mutex             1.0                        cuda    pytorch\ntorchaudio                2.0.2               py311_cu118    pytorch\ntorchtriton               2.0.0                     py311    pytorch\ntorchvision               0.15.2              py311_cu118    pytorch\n\n\n\n!nvcc --version\n\n/bin/bash: line 1: nvcc: command not found\n\n\n\n!pip list | grep \"fastai\" \n!pip list | grep \"fastbook\"\n!pip list | grep \"ipywidgets\"\n\nfastai                    2.7.12\nfastbook                  0.0.29\nipywidgets                7.7.5\n\n\n\nimport torch\n\n\ntorch.cuda.is_available()\n\nTrue"
  },
  {
    "objectID": "lession2.html#gather-data",
    "href": "lession2.html#gather-data",
    "title": "Lession 2:",
    "section": "Gather Data",
    "text": "Gather Data\n\nfrom fastbook import search_images_ddg\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\nimport os\n\n\n\nCode\ndef download_pic(name):   \n    # File path of the image\n    image_path = f'{name}.jpg'\n\n    # Check if the image file exists\n    if os.path.exists(image_path):\n        print(\"Image file exists.\")\n    else:\n        print(\"Image file does not exist.\")\n        download_url(\n            search_images_ddg(f'{name}',\n            max_images=1)[0], f'{name}.jpg',\n            show_progress=False\n        )\n\n    return Image.open(f'{name}.jpg').to_thumb(256,256)\n\n\n\n\ndownload_pic\n\n download_pic (name)\n\n\ndest = 'grizzly'\ndownload_pic(dest)\n\nImage file exists.\n\n\n\n\n\n\n\nCode\ndef create_searches_folder(folder_path, searches):\n    for i in searches:\n        dest = (folder_path/i)\n        dest.mkdir(exist_ok=True, parents=True)\n        print(f'created {i} folder')\n\n\n\n\n\ncreate_searches_folder\n\n create_searches_folder (folder_path, searches)\n\n\n\nCode\ndef download_search_images(folder_path, searches, amount):\n    for j in searches:\n        print(f\"downloading images for: {j}\")\n        download_images(\n            folder_path/j,\n            urls=search_images_ddg(f'{j} photo', amount),\n            n_workers=16\n        )\n\n\n\n\n\ndownload_search_images\n\n download_search_images (folder_path, searches, amount)\n\n\n\nCode\ndef verify_pics(folder_path):\n    failed = verify_images(get_image_files(folder_path))\n    failed.map(Path.unlink)\n    print(f\"Number of images failed: {len(failed)}\")\n\n\n\n\n\nverify_pics\n\n verify_pics (folder_path)\n\n\n\nCode\ndef resize_pics(folder_path, searches):\n    for k in searches:\n        resize_images(\n            folder_path/k,\n            max_size=400,\n            dest=folder_path/k,\n            max_workers=8\n        )\n        print(f\"resizing images for: {k}\")\n\n\n\n\n\nresize_pics\n\n resize_pics (folder_path, searches)\n\n\n\nCode\ndef create_data_folder(folder_path, searches, amount):\n    if os.path.exists(folder_path):\n        print(f\"Folder already exists: {folder_path}\")\n    else:   \n        create_searches_folder(folder_path, searches)\n        download_search_images(folder_path, searches, amount)\n        verify_pics(folder_path)\n        resize_pics(folder_path, searches)\n\n\n\n\n\ncreate_data_folder\n\n create_data_folder (folder_path, searches, amount)\n\n\n\nCode\nsearches = ('grizzly bears','black bears','teddy bears')\npath = Path('bears')\n\ncreate_data_folder(path, searches, 200)\n\n\nFolder already exists: bears"
  },
  {
    "objectID": "lession2.html#data-augmentation-and-designing-model",
    "href": "lession2.html#data-augmentation-and-designing-model",
    "title": "Lession 2:",
    "section": "Data Augmentation and Designing model",
    "text": "Data Augmentation and Designing model\n\n?DataBlock\n\n\nInit signature:\nDataBlock(\n    blocks: 'list' = None,\n    dl_type: 'TfmdDL' = None,\n    getters: 'list' = None,\n    n_inp: 'int' = None,\n    item_tfms: 'list' = None,\n    batch_tfms: 'list' = None,\n    *,\n    get_items=None,\n    splitter=None,\n    get_y=None,\n    get_x=None,\n)\nDocstring:      Generic container to quickly build `Datasets` and `DataLoaders`.\nFile:           ~/mambaforge/envs/fast/lib/python3.11/site-packages/fastai/data/block.py\nType:           type\nSubclasses:     \n\n\n\n\nbears = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\n\n\ndls = bears.dataloaders(path)\n\n\ndls.valid.show_batch(max_n=4, nrows=1)\n\n\n\n\n\nbears = bears.new(item_tfms=Resize(128, ResizeMethod.Squish))\ndls = bears.dataloaders(path)\ndls.valid.show_batch(max_n=4, nrows=1)\n\n\n\n\n\nbears = bears.new(\n    item_tfms=Resize(128, ResizeMethod.Pad, pad_mode='zeros'))\ndls = bears.dataloaders(path)\ndls.valid.show_batch(max_n=4, nrows=1)\n\n\n\n\n\nbears = bears.new(item_tfms=RandomResizedCrop(128, min_scale=0.3))\ndls = bears.dataloaders(path)\ndls.train.show_batch(max_n=4, nrows=1, unique=True)"
  },
  {
    "objectID": "lession2.html#training-your-model-and-using-it-to-clean-your-data",
    "href": "lession2.html#training-your-model-and-using-it-to-clean-your-data",
    "title": "Lession 2:",
    "section": "Training Your Model, and Using It to Clean Your Data",
    "text": "Training Your Model, and Using It to Clean Your Data\n\nbears = bears.new(\n    item_tfms=RandomResizedCrop(128, min_scale=0.5),\n    batch_tfms=aug_transforms(mult=1))\ndls = bears.dataloaders(path)\ndls.train.show_batch(max_n=8, nrows=2, unique=False)\n\n\n\n\n\ndls.valid.show_batch(max_n=8, nrows=2, unique=False)"
  },
  {
    "objectID": "lession2.html#training-your-model",
    "href": "lession2.html#training-your-model",
    "title": "Lession 2:",
    "section": "Training Your Model",
    "text": "Training Your Model\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(6, nrows=2)\n\n\n\n\n\n\n\n\n\n\n\n\nfrom fastai.vision.widgets import ImageClassifierCleaner\n\n\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#hide\n# for idx in cleaner.delete(): cleaner.fns[idx].unlink()\n# for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)"
  },
  {
    "objectID": "lession2.html#testing",
    "href": "lession2.html#testing",
    "title": "Lession 2:",
    "section": "Testing",
    "text": "Testing\n\nsearches = ('grizzly bears','black bears','teddy bears')\nimage= 'grizzly.jpg'\n\n\nis_real,_,probs = learn.predict(PILImage.create(image))\n\nfor index, value in enumerate(searches):\n    np.set_printoptions(suppress=True, precision=4)\n    print(f\"Probability of {value} is :{probs[index]:.5f}.\")\n    \nmax_value, max_index = torch.max(probs, dim=0)\nprint(f\"This is a: {searches[max_index]} with probability: {max_value:.5f}.\")\n\n\nImage.open(image).to_thumb(256,256)\n\n\n\n\n\n\n\n\nProbability of grizzly bears is :0.00002.\nProbability of black bears is :0.99993.\nProbability of teddy bears is :0.00005.\nThis is a: black bears with probability: 0.99993."
  },
  {
    "objectID": "lession2.html#turning-your-model-into-an-online-application",
    "href": "lession2.html#turning-your-model-into-an-online-application",
    "title": "Lession 2:",
    "section": "Turning Your Model into an Online Application",
    "text": "Turning Your Model into an Online Application\n\nlearn.export('model.pkl')\n\n\npath = Path()\nfilename = path.ls(file_exts='.pkl')\nfilename[0].name\n\n'model.pkl'\n\n\n\nlearn_inf = load_learner(path/filename[0].name)\n\n\n\n\n\n\n\n\n\n\n\nCPU times: user 214 ms, sys: 21 ms, total: 235 ms\nWall time: 83.4 ms\n\n\n('grizzly bears', tensor(1), tensor([2.2252e-05, 9.9993e-01, 4.9021e-05]))\n\n\n\nlearn_inf.dls.vocab\n\n['black bears', 'grizzly bears', 'teddy bears']"
  },
  {
    "objectID": "lession2.html#making-a-widget-application",
    "href": "lession2.html#making-a-widget-application",
    "title": "Lession 2:",
    "section": "Making a widget application",
    "text": "Making a widget application\n\nimport ipywidgets as widgets\n\n\nbtn_upload = widgets.FileUpload(\n    accept='',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n    multiple=False  # True to accept multiple files upload else False\n)\nbtn_upload\n\n\n\n\n\nif btn_upload.data != []:\n    img = PILImage.create(btn_upload.data[-1])\n\n\nimg\n\nNameError: name 'img' is not defined\n\n\n\nout_pl = widgets.Output()\nout_pl.clear_output()\nwith out_pl: display(img.to_thumb(128,128))\nout_pl\n\n\n\n\n\npred,pred_idx,probs = learn_inf.predict(img)\n\nNameError: name 'img' is not defined\n\n\n\n#hide_output\nlbl_pred = widgets.Label()\nlbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\nlbl_pred\n\nNameError: name 'pred' is not defined\n\n\n\nbtn_run = widgets.Button(description='Classify')\nbtn_run\n\n\n\n\n\ndef on_click_classify(change):\n    if btn_upload.data != []:\n        img = PILImage.create(btn_upload.data[-1])\n        out_pl.clear_output()\n        with out_pl: display(img.to_thumb(128,128))\n        pred,pred_idx,probs = learn_inf.predict(img)\n        lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\n    else:\n        lbl_pred.value = f'Select image'\n\nbtn_run.on_click(on_click_classify)\n\n\nlbl_pred\n\n\n\n\n\nwidgets.VBox([widgets.Label('Select your bear!'), \n      btn_upload, btn_run, out_pl, lbl_pred])"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "fastAIcourse",
    "section": "",
    "text": "nbdev_prepare\n\nnbdev_prepare\n\nGit stuff\n\ngit add .\ngit commit -m \"update\"\ngit push"
  },
  {
    "objectID": "index.html#step-for-git-push",
    "href": "index.html#step-for-git-push",
    "title": "fastAIcourse",
    "section": "",
    "text": "nbdev_prepare\n\nnbdev_prepare\n\nGit stuff\n\ngit add .\ngit commit -m \"update\"\ngit push"
  },
  {
    "objectID": "index.html#after-changing-dependencies",
    "href": "index.html#after-changing-dependencies",
    "title": "fastAIcourse",
    "section": "After changing dependencies",
    "text": "After changing dependencies\npip install fastAIcourse\npip install -e '.[dev]'"
  },
  {
    "objectID": "02_NeuralNet.html#the-data",
    "href": "02_NeuralNet.html#the-data",
    "title": "Lession 3: Neural Net Foundations",
    "section": "The data",
    "text": "The data\n\nimport pandas as pd\n\n\ndf_results = pd.read_csv('./Data/results-imagenet.csv')\n\n\ndf_results['model_org'] = df_results['model'] \ndf_results['model'] = df_results['model'].str.split('.').str[0]\n\n\ndef get_data(part, col):\n    df = pd.read_csv(f'benchmark-{part}-amp-nhwc-pt111-cu113-rtx3090.csv').merge(df_results, on='model')\n    df['secs'] = 1. / df[col]\n    df['family'] = df.model.str.extract('^([a-z]+?(?:v2)?)(?:\\d|_|$)')\n    df = df[~df.model.str.endswith('gn')]\n    df.loc[df.model.str.contains('in22'),'family'] = df.loc[df.model.str.contains('in22'),'family'] + '_in22'\n    df.loc[df.model.str.contains('resnet.*d'),'family'] = df.loc[df.model.str.contains('resnet.*d'),'family'] + 'd'\n    return df[df.family.str.contains('^re[sg]netd?|beit|convnext|levit|efficient|vit|vgg|swin')]\n\n\ndf = get_data('infer', 'infer_samples_per_sec')\n\nFileNotFoundError: [Errno 2] No such file or directory: 'benchmark-infer-amp-nhwc-pt111-cu113-rtx3090.csv'"
  }
]